---
title: "Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System"
citation_key: "Lissack2024"
authors: "Michael Lissack; Brenden Meagher"
year: "2024"

bibliography: ../../refs/library.bib
csl: https://www.zotero.org/styles/harvard-cite-them-right
link-citations: true
---
[@Lissack2024](Lissack2024.html)


## Summary
- **What is the author saying?**  
  The authors propose an analogy between responsible LLM use and the Oxford Tutorial system, positioning AI as a 'second student'—a partner to human inquiry rather than a replacement. The article explores scenarios where AI can enhance critical thinking, maintain ethical standards, and preserve human expertise.

## Relevance
- **How is it relevant to your research?**  
  Provides a conceptual model for integrating AI into academic and professional contexts without undermining human agency. Offers a grounded way to argue for AI as augmentation rather than automation in creative and research workflows.

## Critical appraisal
- **Strengths**  
  - Innovative analogy that is easy to communicate.
  - Ethical and practical considerations are well balanced.
  - Useful for developing AI use policies in education.
- **Weaknesses / Gaps**  
  - Lacks empirical testing of the analogy’s effectiveness.
  - Primarily a conceptual piece—limited data or case studies.

## Key quotes
- "Integrating sophisticated AI systems into academic practice raises critical questions about responsible use."
- "An analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial."

## Related works
- [@Wilkinson2016] on FAIR principles and responsible data use.
