<!DOCTYPE html>
<html lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System</title>
    <link rel="stylesheet" href="notes.css?v=20250815145826" />
</head>
<body>

<nav class="top-nav">
  <a href="review.html">← Back to Literature Review</a>
  <span> · </span>
  <a href="index.html">All notes</a>
</nav>

<header class="page-header">
  <p class="last-updated">Last updated <span id="last-updated"></span></p>
  <h1 class="title">Responsible Use of Large Language Models: An Analogy
with the Oxford Tutorial System</h1>
  <h3 class="authors">Michael Lissack; Brenden Meagher</h3>
</header>

<main id="content">
<p><a href="Lissack2024.html"><span class="citation"
data-cites="Lissack2024">Lissack and Meagher
(<span>2024</span>)</span></a></p>
<h2 id="summary">Summary</h2>
<ul>
<li><strong>What is the author saying?</strong><br />
The authors propose an analogy between responsible LLM use and the
Oxford Tutorial system, positioning AI as a ‘second student’—a partner
to human inquiry rather than a replacement. The article explores
scenarios where AI can enhance critical thinking, maintain ethical
standards, and preserve human expertise.</li>
</ul>
<h2 id="relevance">Relevance</h2>
<ul>
<li><strong>How is it relevant to your research?</strong><br />
Provides a conceptual model for integrating AI into academic and
professional contexts without undermining human agency. Offers a
grounded way to argue for AI as augmentation rather than automation in
creative and research workflows.</li>
</ul>
<h2 id="critical-appraisal">Critical appraisal</h2>
<ul>
<li><strong>Strengths</strong>
<ul>
<li>Innovative analogy that is easy to communicate.</li>
<li>Ethical and practical considerations are well balanced.</li>
<li>Useful for developing AI use policies in education.</li>
</ul></li>
<li><strong>Weaknesses / Gaps</strong>
<ul>
<li>Lacks empirical testing of the analogy’s effectiveness.</li>
<li>Primarily a conceptual piece—limited data or case studies.</li>
</ul></li>
</ul>
<h2 id="key-quotes">Key quotes</h2>
<ul>
<li>“Integrating sophisticated AI systems into academic practice raises
critical questions about responsible use.”</li>
<li>“An analogy between the optimal use of LLMs and the role of the
second student in an Oxford Tutorial.”</li>
</ul>
<h2 id="related-works">Related works</h2>
<ul>
<li><span class="citation" data-cites="Wilkinson2016">(<a
href="#ref-Wilkinson2016" role="doc-biblioref">Wilkinson <em>et
al.</em>, 2016</a>)</span> on FAIR principles and responsible data
use.</li>
</ul>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-Lissack2024" class="csl-entry" role="listitem">
Lissack, M. and Meagher, B. (2024) <span>‘Responsible use of large
language models: An analogy with the oxford tutorial system’</span>,
<em>She Ji: The Journal of Design, Economics, and Innovation</em>, 10,
pp. 389–413. Available at: <a
href="https://doi.org/10.1016/j.sheji.2024.11.001">https://doi.org/10.1016/j.sheji.2024.11.001</a>.
</div>
<div id="ref-Wilkinson2016" class="csl-entry" role="listitem">
Wilkinson, M.D. <em>et al.</em> (2016) <span>‘Comment: The FAIR guiding
principles for scientific data management and stewardship’</span>,
<em>Scientific Data</em>, 3. Available at: <a
href="https://doi.org/10.1038/sdata.2016.18">https://doi.org/10.1038/sdata.2016.18</a>.
</div>
</div>
</main>

<script>
  // Put the file’s modified date under the authors line
  (function () {
    var el = document.getElementById('last-updated');
    if (el) el.textContent = new Date(document.lastModified)
      .toLocaleDateString(undefined, { day:'2-digit', month:'long', year:'numeric' });
  }());
</script>

</body>
</html>